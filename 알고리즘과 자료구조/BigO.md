![](https://images.velog.io/images/prettylee620/post/7df75285-49fb-4550-b1e1-c9074b8063e8/image.png)
## ⚾ 공부하기 전 알고리즘이 필요한 이유
- 배열 안에 있는 숫자를 **어떻게 찾을 수 있는가?**
- 어떤 알고리즘을 `선택`하느냐에 따라 속도가 빨라짐
- 어떤 자료구조를 언제 선택하는지 중요한 것처럼 무슨 알고리즘을 언제 선택하는지 배워야 함
- 이유 : 완벽한 자료구조, 알고리즘의 조합을 찾아내면 **코드의 스피드**가 달라짐
- 우리 생활 속의 알고리즘은 예를 들면, 레시피 같은 존재


## ⚾ 개요
1. 알고리즘의 **스피드**를 어떻게 표현하는지 알아봄

2. 빠르다, 느리다의 말이 아닌 `CS지식`

3. “빠르다”, “느리다”는 `시간`으로 **표현하지 않음(시간 복잡도)**
    >* 같은 알고리즘이라도 내 컴퓨터가 친구의 컴퓨터보다 빠를 수 있음
    * 컴퓨터라는 하드웨어가 결정하기 때문
    * “완료까지 걸리는 절차의 수” : `STEPS`
    * 알고리즘을 위해 필요한 연산의 횟수
    * 특정 크기의 입력에 대하여 알고리즘이 얼마나 오래 걸리는지
    
4. 선형 알고리즘의 경우 사이즈가 **N**개이면, **N**스텝이 필요함
5. **공간복잡도** : 특정한 크기의 입력에 대하여 알고리즘이 얼마나 많은 `메모리`를 차지하는지
   ⇒ 알고리즘을 위해 필요한 메모리의 양
    

## ⚾ Big O
- Big O란 시간복잡도를 표현하는 **표기법**
- 선형검색의 시간 복잡도 = `O(N)`
- 알고리즘의 퍼포먼스를 이해하기 쉽고 `효율적`으로 작성하는 방법
- Big O를 이해시, 알고리즘을 **빠르게 분석** 가능, 언제 무엇을 쓸지 파악 가능
- but, 항상 Big O가 모든 알고리즘을 완벽히 설명하는 것은 아님
- 배열을 인풋으로 사용할 함수, 인풋의 크기 상관없이 **동일한 수의 스텝**이 필요 : `인덱스`를 이용하여 한 번에 찾으니까

```python
def print_first(arr):
		print(arr[0])
```
> 이 함수의 시간복잡도는 `constant time(상수 시간)` : **N의 크기 상관없이** 끝내는데 동일한 숫자의 스텝이 필요
> ![](https://images.velog.io/images/prettylee620/post/89b0c0bf-efa5-4547-84c1-75fda3997b3c/image.png)

```python
def print_first(arr):
		print(arr[0])
		print(arr[0])
```

>Q. 코드가 위와 같다면 O[2] 일까? 
A. NO! 여전히 `O[1]`
>>- Big O는 함수의 디테일에 관심이 없고, 러프하게 어떻게 이 함수가 `인풋의 사이즈`에 따라서 어떻게 작동하는지가 중요
- 함수는 인풋 사이즈가 엄청나게 커져도 상관없이 미리 정해진 숫자에 따라 작동
⇒ `상수`를 신경 쓰지 않음
    

## ⚾ Constant Time Algorithm(상수 시간 알고리즘)
- constant time `(일정한 시간/상수)`
- 인풋사이즈와 관계없이 스텝이 정해진 알고리즘들
- 항상 선호하는 것 ⇒ 인풋이 늘어나도 **변하지 않음**
- 현실적으로 **항상** 만들기 힘들다

![](https://images.velog.io/images/prettylee620/post/5d25e228-28f4-47a9-b021-bb6125f5d7be/image.png)

## ⚾ 시간복잡도 1: Big O의 시간복잡도, 선형 시간 복잡도
배열의 사이즈가 10이라면, 10번 프린트 하는 함수 : **O(N)**

```python
def print_all(arr):
	for n in arr:
		print(n)
```

>Q: 만약 반복문을 두번이라면 `O(2N)`일까? 
>```python
def print_all(arr):
	for n in arr:
		print(n)
	for n in arr:
		print(n)
```
A: **2는 상수**이기에 **버려두고**, 여전히 `O(N)`으로 표현, 핵심은 변하지 않았지 때문
메세지가 같다 ⇒ `인풋이 증가`하면 `스텝도 선형적으로 증가`

### 🎈 O(N)이나 선형 시간복잡도를 그래프

![](https://images.velog.io/images/prettylee620/post/461c8084-a827-4bd3-96db-da854b807b25/image.png)

## ⚾ 시간복잡도 2 : Quadratic Time(2차 시간)
- **`Nested Loops(중첩 반복)`**이 있을 때, 발생
- 아래의 경우 배열의 각 아이템에 대해 루프를 반복, 실행

```python
def print_twice(arr)
	for n in arr:
		for x in arr:
			print(x, n)
```

- 시간복잡도 : **인풋 $n^2$**
    
    EX. 인풋이 10개시 100번의 스텝 : **루프 안의 루프**에서 함수를 실행시키기 때문
    

### 🎈 2차 시간복잡도 그래프를 선형 시간복잡도와 비교 그래프

![](https://images.velog.io/images/prettylee620/post/a3d75b34-e431-49fc-8e6f-4b7eb41610e4/image.png)

**선형 시간복잡도**가 2차 시간복잡도보다 더 **효율적**

## ⚾ 시간복잡도 3 : 로그 시간(Logarithmic Time)

---

- 이진검색 알고리즘 설명시 사용 ⇒ 얼마나 `빠른지` 설명 가능
- 표현법 :  `O(log N)`
- 정렬된 배열에만 사용 가능
- exponent(지수) ↔ logarithm(로그)
- n = $log_232$ n은 몇번을 나눠야 1이 나올까? n은 5
    
    ⇒ 이진 검색과 같음 인풋을 반으로 나누고 시작하는 것처럼
    
    ⇒ Big O의 특성상 n = $log32$ 아래의 2가 사라짐
    
    ⇒ So, `log N`이 되는 것
    
- ### 🎈 로그 시간복잡도의 **그래프**

![](https://images.velog.io/images/prettylee620/post/3cd7bd7f-77b0-42ee-a8ea-7956ceef41af/image.png)

**선형시간**보다는 `빠르고`, **상수 시간**보다는 `느림`
